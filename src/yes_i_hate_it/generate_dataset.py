"""Generate cvs dataset"""
import sys
import csv
import logging
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine

from yes_i_hate_it.gather_tweets import Tweet
from yes_i_hate_it.generate_bow import Word, process_text

from yes_i_hate_it.config import DATASET_FILE_PATH, DATASET_LOG_FILE
from yes_i_hate_it.config import TWEETS_DB_PATH


def get_tweets(session, amount):
    """Get labeled tweets from the database"""
    # pylint: disable = singleton-comparison
    tweets = session.query(Tweet).filter(Tweet.labeled==True, Tweet.processed==True).limit(amount).all()
    for tweet in tweets:
        tweet.processed = False
        session.add(tweet)
    session.commit()
    return tweets


def from_text_to_array(session, text):
    """Convert given text into numpy array obtained using bow and with labels included"""
    total_words = session.query(Word).count()
    data = [0 for _ in range(total_words)]

    processed_words = process_text(text)
    for word in processed_words:
        db_word = session.query(Word).filter(Word.text==word).first()
        data[db_word.id-1] = 1
    return data


def from_label_to_array(label):
    """Return list with labels generated by given tweet label"""
    # label = 0: not football
    # label = 1: football
    labels = {1: [1, 0], 0: [0, 1]}
    return labels[label]


def main():
    """Main function"""
    if not TWEETS_DB_PATH.exists():
        logging.info("Database does not exists")
        sys.exit()

    # pylint: disable = no-member
    DATASET_LOG_FILE.parents[0].mkdir(exist_ok=True)
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s - %(levelname)s - %(message)s",
        handlers=[
            logging.FileHandler(DATASET_LOG_FILE),
            logging.StreamHandler()
        ]
    )

    engine = create_engine(f'sqlite:///{TWEETS_DB_PATH}')
    session_maker = sessionmaker(bind=engine)
    session = session_maker()

    words = session.query(Word).all()
    words_list = []
    for word in words:
        words_list.append(word.text)

    words.extend(['football', 'no_football'])
    with open(DATASET_FILE_PATH, 'w', encoding='UTF-8') as handle:
        writer = csv.writer(handle)
        writer.writerow(words_list)

    step = 500
    tweets = get_tweets(session, step)
    while tweets:
        for tweet in tweets:
            row = from_text_to_array(session, tweet.text)
            row += from_label_to_array(tweet.is_football)

            with open(DATASET_FILE_PATH, 'a', encoding='UTF-8') as handle:
                writer = csv.writer(handle)
                writer.writerow(row)
        tweets = get_tweets(session, step)


if __name__ == '__main__':
    main()
